{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_BOW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWajG9MJ9Hao"
      },
      "source": [
        "# Bag of Words BOW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkNYLg_u9PBP"
      },
      "source": [
        "* 단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFGb8JcG-wz_"
      },
      "source": [
        "## 1. Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iB43O7grWZF"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = ['you know I want your love. becuase I love you.']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnDBXDpDA7HZ"
      },
      "source": [
        "cvector = CountVectorizer()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P65eR-7A8Fa",
        "outputId": "b5dc34f1-ae18-4f77-944b-1a6c014b5a9b"
      },
      "source": [
        "cvector.fit(corpus)                     # fit 학습(모델은 데이터와 결과를 가지고 있고 이것을 학습하는데 fit을 이때 씀)\n",
        "cvector.transform(corpus).toarray()     # transform 변환 - 희소성의 문제로 그 자체는 안되고 .toarray 해줘야 함"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 2, 1, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHKK_JnJBqY7",
        "outputId": "bdc76381-e932-47ef-8b9b-fb3a1f5d559e"
      },
      "source": [
        "cvector.vocabulary_"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'becuase': 0, 'know': 1, 'love': 2, 'want': 3, 'you': 4, 'your': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWMNI6ibB5xp",
        "outputId": "4f6fd84c-5892-418c-93c9-d3c149507c77"
      },
      "source": [
        " output = cvector.fit_transform(corpus).toarray()\n",
        " output"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 2, 1, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiOzoMV5Cxj8",
        "outputId": "3790fec2-4068-4a61-9db2-b300371bdc25"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywIG-SIUC5v5"
      },
      "source": [
        "* 불용어를 제거한 BoW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3EVcQVnC8fM",
        "outputId": "60438092-4b52-447c-d37c-0cfcdc396a5b"
      },
      "source": [
        "# 사용자 정의\n",
        "text=[\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words=[\"the\", \"a\", \"an\", \"is\", \"not\"])\n",
        "print(vect.fit_transform(text).toarray()) \n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1]]\n",
            "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lytQEiHOF5mS",
        "outputId": "3d149ce6-0587-41b6-f3e6-f6df2ad0983c"
      },
      "source": [
        "# Scikit-Learn 제공\n",
        "text=[\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words=\"english\")\n",
        "print(vect.fit_transform(text).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1]]\n",
            "{'family': 0, 'important': 1, 'thing': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKeVBcj2GOl8",
        "outputId": "217f4920-3d2a-414a-80b1-ff0cfdf8cff9"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXRHeNi2GSo2",
        "outputId": "96a76ae3-e4e5-4c1d-e805-d7c98396b398"
      },
      "source": [
        "# NLTK 제공\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "text=[\"Family is not an important thing. It's everything.\"]\n",
        "sw = stopwords.words(\"english\")\n",
        "vect = CountVectorizer(stop_words =sw)\n",
        "print(vect.fit_transform(text).toarray()) \n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1]]\n",
            "{'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7tCMk7hGxSX"
      },
      "source": [
        "def get_word(index, voca):\n",
        "  for key, value in voca.items():\n",
        "    if value == index:\n",
        "      return key"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RiSJR1l_G9CH",
        "outputId": "75abb2e0-12cc-4865-ef04-721576e67f28"
      },
      "source": [
        "get_word(2, vect.vocabulary_)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'important'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JCYi08CILLP"
      },
      "source": [
        "* N-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOo_1J7oHDGy"
      },
      "source": [
        "text1 = ['Machine learning is fun and not boring.']\n",
        "text2 = ['Machine is boring and learning is not fun.']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYVRbwt4IXBI",
        "outputId": "45cb2623-2445-4815-9e55-ec476e0b8a09"
      },
      "source": [
        "vect = CountVectorizer()\n",
        "print(vect.fit_transform(text1).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1 1 1]]\n",
            "{'machine': 5, 'learning': 4, 'is': 3, 'fun': 2, 'and': 0, 'not': 6, 'boring': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7cmsCftIfWk",
        "outputId": "e6c84cdc-1b29-4dea-bd86-cbe2ea9f8a30"
      },
      "source": [
        "vect = CountVectorizer()\n",
        "print(vect.fit_transform(text2).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 2 1 1 1]]\n",
            "{'machine': 5, 'is': 3, 'boring': 1, 'and': 0, 'learning': 4, 'not': 6, 'fun': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gPaxfOfI0TL",
        "outputId": "0478f326-e619-455d-8602-10c8ff61fad7"
      },
      "source": [
        "# N-gram range: (1, 2)\n",
        "vect = CountVectorizer(ngram_range=(1, 2))\n",
        "print(vect.fit_transform(text1).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
            "{'machine': 9, 'learning': 7, 'is': 5, 'fun': 3, 'and': 0, 'not': 11, 'boring': 2, 'machine learning': 10, 'learning is': 8, 'is fun': 6, 'fun and': 4, 'and not': 1, 'not boring': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msaHdueZJDWl",
        "outputId": "4159e0eb-2139-4eae-a6ba-77f1aada9487"
      },
      "source": [
        "vect = CountVectorizer(ngram_range=(1, 2))\n",
        "print(vect.fit_transform(text2).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1 2 1 1 1 1 1 1 1 1]]\n",
            "{'machine': 10, 'is': 5, 'boring': 2, 'and': 0, 'learning': 8, 'not': 12, 'fun': 4, 'machine is': 11, 'is boring': 6, 'boring and': 3, 'and learning': 1, 'learning is': 9, 'is not': 7, 'not fun': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eM-SA4AJRCx",
        "outputId": "23cfd1c1-0ba5-4a12-ce17-50747bbea23c"
      },
      "source": [
        "vect = CountVectorizer(ngram_range=(1, 3), stop_words=('english'))\n",
        "print(vect.fit_transform(text1).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1 1 1 1 1]]\n",
            "{'machine': 6, 'learning': 3, 'fun': 1, 'boring': 0, 'machine learning': 7, 'learning fun': 4, 'fun boring': 2, 'machine learning fun': 8, 'learning fun boring': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgQ3QsY4J5SJ"
      },
      "source": [
        "* Hyper parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl50a6PuJl72",
        "outputId": "c127f8d2-262a-40d2-d25f-c2cec027c5a4"
      },
      "source": [
        "vect.get_params()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'analyzer': 'word',\n",
              " 'binary': False,\n",
              " 'decode_error': 'strict',\n",
              " 'dtype': numpy.int64,\n",
              " 'encoding': 'utf-8',\n",
              " 'input': 'content',\n",
              " 'lowercase': True,\n",
              " 'max_df': 1.0,\n",
              " 'max_features': None,\n",
              " 'min_df': 1,\n",
              " 'ngram_range': (1, 3),\n",
              " 'preprocessor': None,\n",
              " 'stop_words': 'english',\n",
              " 'strip_accents': None,\n",
              " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'tokenizer': None,\n",
              " 'vocabulary': None}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8eiux_6KpaV"
      },
      "source": [
        "* DTM : 각 문서에 대한 BoW 표현 방법을 그대로 갖고와서, 서로 다른 문서들의 BoW들을 결합한 표현 방법인 문서 단어 행렬(Document-Term Matrix, DTM) - 다수의 문서에서 등장하는 각 단어들의 빈도를 행렬로 표현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnI_Hat6J_4O",
        "outputId": "1de139c0-b8cc-4c33-8027-731bef799e9a"
      },
      "source": [
        "corpus = [\n",
        "          \"you know I want your love\",\n",
        "          \"I like you\",\n",
        "          \"what should I do\"\n",
        "]\n",
        "vect = CountVectorizer()\n",
        "print(vect.fit_transform(corpus).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 1 0 1 0 1 1]\n",
            " [0 0 1 0 0 0 0 1 0]\n",
            " [1 0 0 0 1 0 1 0 0]]\n",
            "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij97Oti5KoP1"
      },
      "source": [
        "### TF-IDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSfw4qc6LK8O",
        "outputId": "8f4aa266-244f-4613-9174-e2c5f8dd907a"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tvect = TfidfVectorizer()\n",
        "print(tvect.fit_transform(corpus).toarray().round(2))\n",
        "print(tvect.vocabulary_)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   0.47 0.   0.47 0.   0.47 0.   0.36 0.47]\n",
            " [0.   0.   0.8  0.   0.   0.   0.   0.61 0.  ]\n",
            " [0.58 0.   0.   0.   0.58 0.   0.58 0.   0.  ]]\n",
            "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6EkuI7oOZ3S",
        "outputId": "71833153-0ef8-42af-d215-0d00e0262612"
      },
      "source": [
        "# n-gram\n",
        "tvect = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')\n",
        "print(tvect.fit_transform(corpus).toarray().round(2))\n",
        "print(tvect.vocabulary_)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.45 0.45 0.   0.45 0.45 0.45]\n",
            " [0.   0.   1.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.  ]]\n",
            "{'know': 0, 'want': 4, 'love': 3, 'know want': 1, 'want love': 5, 'like': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nGe49C_PJpF",
        "outputId": "bc23f3f3-bf63-4324-939b-a4796a8890b6"
      },
      "source": [
        "# Hyper parameter\n",
        "tvect.get_params()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'analyzer': 'word',\n",
              " 'binary': False,\n",
              " 'decode_error': 'strict',\n",
              " 'dtype': numpy.float64,\n",
              " 'encoding': 'utf-8',\n",
              " 'input': 'content',\n",
              " 'lowercase': True,\n",
              " 'max_df': 1.0,\n",
              " 'max_features': None,\n",
              " 'min_df': 1,\n",
              " 'ngram_range': (1, 2),\n",
              " 'norm': 'l2',\n",
              " 'preprocessor': None,\n",
              " 'smooth_idf': True,\n",
              " 'stop_words': 'english',\n",
              " 'strip_accents': None,\n",
              " 'sublinear_tf': False,\n",
              " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'tokenizer': None,\n",
              " 'use_idf': True,\n",
              " 'vocabulary': None}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VvBapi_PUWD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}